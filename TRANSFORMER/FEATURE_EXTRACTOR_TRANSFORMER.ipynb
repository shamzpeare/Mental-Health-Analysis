{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING**"
      ],
      "metadata": {
        "id": "3k1HMaQgQJ8D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "5_ApOUO7PZ8X",
        "outputId": "b934bf07-6f5e-4c4a-e8be-9bceb53494b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "status\n",
              "1    36692\n",
              "0    16351\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "import pandas as pd\n",
        "file_path = 'Combined Data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "def preprocess_and_tokenize(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text.lower())\n",
        "    tokens = simple_preprocess(text, deacc=True)\n",
        "    tokens = [word for word in tokens if word not in ENGLISH_STOP_WORDS]\n",
        "    return tokens\n",
        "\n",
        "df['tokens'] = df['statement'].apply(preprocess_and_tokenize)\n",
        "def get_average_word2vec(tokens, model, vector_size=300):\n",
        "    vectors = [model[word] for word in tokens if word in model]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)\n",
        "\n",
        "df['word2vec_vector'] = df['tokens'].apply(lambda x: get_average_word2vec(x, word2vec_model))\n",
        "\n",
        "\n",
        "df['status'] = df['status'].apply(lambda x: 0 if x == 'Normal' else 1)\n",
        "\n",
        "df['status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENSEMBLE TECHNIQUES**"
      ],
      "metadata": {
        "id": "a6Zm6-3kSXvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "X = np.stack(df['word2vec_vector'].values)\n",
        "y = df['status'].values\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "8-06a_1HSQAp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :].to(x.device)\n",
        "\n",
        "class TransformerFeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_size, d_model=128, num_heads=4, num_layers=2):\n",
        "        super(TransformerFeatureExtractor, self).__init__()\n",
        "        self.embedding = nn.Linear(input_size, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, dim_feedforward=256, dropout=0.1, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x.mean(dim=1)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = TransformerFeatureExtractor(input_size=X_train.shape[1]).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, _ in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "train_features = []\n",
        "train_labels = []\n",
        "test_features = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        features = model(inputs).cpu().numpy()\n",
        "        train_features.extend(features)\n",
        "        train_labels.extend(labels.numpy())\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        features = model(inputs).cpu().numpy()\n",
        "        test_features.extend(features)\n",
        "        test_labels.extend(labels.numpy())\n",
        "\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(train_features, train_labels)\n",
        "svm_preds = svm_classifier.predict(test_features)\n",
        "svm_acc = accuracy_score(test_labels, svm_preds)\n",
        "print(f\"SVM Accuracy: {svm_acc:.2f}\")\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(train_features, train_labels)\n",
        "dt_preds = dt_classifier.predict(test_features)\n",
        "dt_acc = accuracy_score(test_labels, dt_preds)\n",
        "print(f\"Decision Tree Accuracy: {dt_acc:.2f}\")\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
        "rf_classifier.fit(train_features, train_labels)\n",
        "rf_preds = rf_classifier.predict(test_features)\n",
        "rf_acc = accuracy_score(test_labels, rf_preds)\n",
        "print(f\"Random Forest Accuracy: {rf_acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiHywRibSV7f",
        "outputId": "b17d5c52-e021-4296-afc4-b6aa5b07ffd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.90\n",
            "Decision Tree Accuracy: 0.83\n",
            "Random Forest Accuracy: 0.90\n"
          ]
        }
      ]
    }
  ]
}